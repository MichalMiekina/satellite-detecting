{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file generated_images, as it is not a valid image.\n",
      "Loaded 13 valid images, skipped 1 invalid images.\n",
      "Dataset shape: (13, 64, 64, 3)\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "0 [D loss: 0.7331022918224335, acc.: 9.375] [G loss: 0.5459686517715454]\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1 [D loss: 0.49187377095222473, acc.: 50.0] [G loss: 0.4174857437610626]\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "2 [D loss: 0.41087519749999046, acc.: 50.0] [G loss: 0.31225693225860596]\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "3 [D loss: 0.3720192089676857, acc.: 65.625] [G loss: 0.24477490782737732]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "4 [D loss: 0.3351338282227516, acc.: 100.0] [G loss: 0.17825844883918762]\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "5 [D loss: 0.27456505689769983, acc.: 100.0] [G loss: 0.12314867228269577]\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "6 [D loss: 0.18330185394734144, acc.: 100.0] [G loss: 0.07749400287866592]\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "7 [D loss: 0.08295377111062407, acc.: 100.0] [G loss: 0.04649624973535538]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "8 [D loss: 0.03343055513687432, acc.: 100.0] [G loss: 0.027365952730178833]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "9 [D loss: 0.015924662118777633, acc.: 100.0] [G loss: 0.020301448181271553]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "10 [D loss: 0.010285346768796444, acc.: 100.0] [G loss: 0.014397438615560532]\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "11 [D loss: 0.01005992735736072, acc.: 100.0] [G loss: 0.0115336449816823]\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "12 [D loss: 0.010796042275615036, acc.: 100.0] [G loss: 0.009712662547826767]\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "13 [D loss: 0.012400449835695326, acc.: 100.0] [G loss: 0.007847284898161888]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "14 [D loss: 0.018437360122334212, acc.: 100.0] [G loss: 0.006932266056537628]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "15 [D loss: 0.02038221326074563, acc.: 100.0] [G loss: 0.006397496908903122]\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "16 [D loss: 0.025894517864799127, acc.: 100.0] [G loss: 0.006640508305281401]\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "17 [D loss: 0.02537405524344649, acc.: 100.0] [G loss: 0.00712731946259737]\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "18 [D loss: 0.02536415189388208, acc.: 100.0] [G loss: 0.011253043077886105]\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "19 [D loss: 0.016295809371513315, acc.: 100.0] [G loss: 0.01696937158703804]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "20 [D loss: 0.007085700810421258, acc.: 100.0] [G loss: 0.020086824893951416]\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "21 [D loss: 0.010710893431678414, acc.: 100.0] [G loss: 0.024083271622657776]\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "22 [D loss: 0.026451828656718135, acc.: 100.0] [G loss: 0.05358825996518135]\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "23 [D loss: 0.3149607377126813, acc.: 84.375] [G loss: 1.8028581142425537]\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "24 [D loss: 1.3320585638284683, acc.: 50.0] [G loss: 0.2995198369026184]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "25 [D loss: 0.5388506129384041, acc.: 50.0] [G loss: 1.1635773181915283]\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "26 [D loss: 1.3055089116096497, acc.: 0.0] [G loss: 0.16429544985294342]\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "27 [D loss: 0.48654206097126007, acc.: 51.5625] [G loss: 0.29862865805625916]\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "28 [D loss: 0.42399121820926666, acc.: 84.375] [G loss: 0.6358233094215393]\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "29 [D loss: 0.8078524470329285, acc.: 50.0] [G loss: 1.0441993474960327]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "30 [D loss: 0.9015019834041595, acc.: 3.125] [G loss: 0.8267203569412231]\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "31 [D loss: 0.7729492485523224, acc.: 40.625] [G loss: 0.7411243915557861]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "32 [D loss: 0.7074297964572906, acc.: 50.0] [G loss: 0.767223596572876]\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "33 [D loss: 0.682147741317749, acc.: 51.5625] [G loss: 0.7690463662147522]\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "34 [D loss: 0.7368004024028778, acc.: 43.75] [G loss: 0.7195897102355957]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "35 [D loss: 0.7520787119865417, acc.: 45.3125] [G loss: 0.7375422716140747]\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "36 [D loss: 0.6999152600765228, acc.: 51.5625] [G loss: 0.8342940211296082]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "37 [D loss: 0.6768684089183807, acc.: 57.8125] [G loss: 0.912918210029602]\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "38 [D loss: 0.6514670252799988, acc.: 70.3125] [G loss: 0.9105191230773926]\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "39 [D loss: 0.6555914282798767, acc.: 54.6875] [G loss: 0.8471358418464661]\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "40 [D loss: 0.6043357253074646, acc.: 75.0] [G loss: 0.7603802680969238]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "41 [D loss: 0.6723228693008423, acc.: 59.375] [G loss: 0.6280508041381836]\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "42 [D loss: 0.7629248201847076, acc.: 45.3125] [G loss: 0.7440019249916077]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "43 [D loss: 0.7953744232654572, acc.: 34.375] [G loss: 0.7739599943161011]\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "44 [D loss: 0.8411594927310944, acc.: 15.625] [G loss: 0.7179579734802246]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "45 [D loss: 0.8623034060001373, acc.: 14.0625] [G loss: 0.6880446672439575]\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "46 [D loss: 0.8282546401023865, acc.: 34.375] [G loss: 0.7294931411743164]\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "47 [D loss: 0.8486952483654022, acc.: 9.375] [G loss: 0.7199923396110535]\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "48 [D loss: 0.8309676647186279, acc.: 28.125] [G loss: 0.7023696899414062]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "49 [D loss: 0.780937910079956, acc.: 37.5] [G loss: 0.7442975044250488]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "50 [D loss: 0.8287073969841003, acc.: 18.75] [G loss: 0.700496256351471]\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "51 [D loss: 0.8021417260169983, acc.: 32.8125] [G loss: 0.7346670627593994]\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "52 [D loss: 0.8063893914222717, acc.: 25.0] [G loss: 0.7320299744606018]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "53 [D loss: 0.8264603018760681, acc.: 14.0625] [G loss: 0.7118513584136963]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "54 [D loss: 0.7915568053722382, acc.: 34.375] [G loss: 0.7684271931648254]\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "55 [D loss: 0.8016231954097748, acc.: 17.1875] [G loss: 0.7365826368331909]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "56 [D loss: 0.7894050478935242, acc.: 26.5625] [G loss: 0.7505831718444824]\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "57 [D loss: 0.7867292761802673, acc.: 26.5625] [G loss: 0.72744220495224]\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "58 [D loss: 0.7878162562847137, acc.: 28.125] [G loss: 0.7253463268280029]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "59 [D loss: 0.7839164435863495, acc.: 29.6875] [G loss: 0.7550356388092041]\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "60 [D loss: 0.7881892323493958, acc.: 15.625] [G loss: 0.7175220847129822]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "61 [D loss: 0.781158983707428, acc.: 26.5625] [G loss: 0.7460448741912842]\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "62 [D loss: 0.781413733959198, acc.: 28.125] [G loss: 0.7581163048744202]\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "63 [D loss: 0.7831586599349976, acc.: 23.4375] [G loss: 0.731322705745697]\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "64 [D loss: 0.7814639210700989, acc.: 25.0] [G loss: 0.7484585046768188]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "65 [D loss: 0.7708266973495483, acc.: 20.3125] [G loss: 0.7782090902328491]\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "66 [D loss: 0.8022076189517975, acc.: 12.5] [G loss: 0.716903030872345]\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "67 [D loss: 0.769827276468277, acc.: 35.9375] [G loss: 0.7310566902160645]\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "68 [D loss: 0.7640368342399597, acc.: 25.0] [G loss: 0.7499892115592957]\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "69 [D loss: 0.7682891488075256, acc.: 25.0] [G loss: 0.7548388242721558]\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "70 [D loss: 0.7811177372932434, acc.: 18.75] [G loss: 0.7212430238723755]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "71 [D loss: 0.7680526971817017, acc.: 28.125] [G loss: 0.7354591488838196]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "72 [D loss: 0.7683556973934174, acc.: 23.4375] [G loss: 0.7403185367584229]\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "73 [D loss: 0.7744738161563873, acc.: 20.3125] [G loss: 0.727117657661438]\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "74 [D loss: 0.7521303296089172, acc.: 31.25] [G loss: 0.7652080059051514]\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "75 [D loss: 0.7858364284038544, acc.: 7.8125] [G loss: 0.721381425857544]\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "76 [D loss: 0.7673215568065643, acc.: 32.8125] [G loss: 0.7261601686477661]\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "77 [D loss: 0.7501697540283203, acc.: 31.25] [G loss: 0.749190092086792]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "78 [D loss: 0.7798789441585541, acc.: 17.1875] [G loss: 0.7078897356987]\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "79 [D loss: 0.7594519257545471, acc.: 26.5625] [G loss: 0.7055046558380127]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "80 [D loss: 0.7512337565422058, acc.: 25.0] [G loss: 0.7472776174545288]\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "81 [D loss: 0.7567041218280792, acc.: 20.3125] [G loss: 0.7166416645050049]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "82 [D loss: 0.762258768081665, acc.: 26.5625] [G loss: 0.7111513018608093]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "83 [D loss: 0.7460259199142456, acc.: 23.4375] [G loss: 0.7353758215904236]\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "84 [D loss: 0.7791688144207001, acc.: 12.5] [G loss: 0.6993364691734314]\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "85 [D loss: 0.7511413097381592, acc.: 34.375] [G loss: 0.7228604555130005]\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "86 [D loss: 0.7437248826026917, acc.: 25.0] [G loss: 0.7387751340866089]\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "87 [D loss: 0.7696505784988403, acc.: 12.5] [G loss: 0.7039526700973511]\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "88 [D loss: 0.7487733662128448, acc.: 34.375] [G loss: 0.7109330892562866]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "89 [D loss: 0.7663658559322357, acc.: 12.5] [G loss: 0.7194967865943909]\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "90 [D loss: 0.7642726004123688, acc.: 21.875] [G loss: 0.686479389667511]\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "91 [D loss: 0.7473785877227783, acc.: 32.8125] [G loss: 0.7226592302322388]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "92 [D loss: 0.7518094480037689, acc.: 31.25] [G loss: 0.7056518793106079]\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "93 [D loss: 0.7562165260314941, acc.: 15.625] [G loss: 0.6997823715209961]\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "94 [D loss: 0.7515524923801422, acc.: 28.125] [G loss: 0.7020770311355591]\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "95 [D loss: 0.7545419931411743, acc.: 26.5625] [G loss: 0.712163507938385]\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "96 [D loss: 0.7606379687786102, acc.: 20.3125] [G loss: 0.6893370151519775]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "97 [D loss: 0.745806485414505, acc.: 28.125] [G loss: 0.7050513029098511]\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "98 [D loss: 0.7405852377414703, acc.: 17.1875] [G loss: 0.6982975006103516]\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "99 [D loss: 0.7491317391395569, acc.: 20.3125] [G loss: 0.689110517501831]\n",
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "# Create a nested folder for the generated images\n",
    "output_folder = './Data/fits_filtered8/generated_images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Step 2: Load and Preprocess Dataset\n",
    "def load_images_from_folder(folder, image_size=(64, 64)):\n",
    "    images = []\n",
    "    valid_files = 0\n",
    "    invalid_files = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            img = load_img(os.path.join(folder, filename), target_size=image_size)\n",
    "            if img is not None:\n",
    "                images.append(img_to_array(img))\n",
    "                valid_files += 1\n",
    "            else:\n",
    "                invalid_files += 1\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            print(f\"Skipping file {filename}, as it is not a valid image.\")\n",
    "            invalid_files += 1\n",
    "    print(f\"Loaded {valid_files} valid images, skipped {invalid_files} invalid images.\")\n",
    "    return np.array(images)\n",
    "\n",
    "dataset = load_images_from_folder('./Data/fits_filtered8')\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "if dataset.size == 0:\n",
    "    raise ValueError(\"No valid images found in the dataset. Please check the image files.\")\n",
    "dataset = (dataset - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "\n",
    "# Step 3: Build the GAN\n",
    "\n",
    "# Generator\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128 * 16 * 16, activation=\"relu\", input_dim=100))\n",
    "    model.add(layers.Reshape((16, 16, 128)))\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.Conv2D(3, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.Activation(\"tanh\"))\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, input_shape=(64, 64, 3), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# The generator takes noise as input and generates images\n",
    "z = layers.Input(shape=(100,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model, only the generator is trained\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n",
    "\n",
    "# The combined model (stacked generator and discriminator)\n",
    "combined = tf.keras.Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n",
    "\n",
    "# Step 4: Train the GAN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Training parameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "save_interval = 1000\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "X_train = dataset\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "# Training the GAN\n",
    "for epoch in range(epochs):\n",
    "    # Train Discriminator\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    valid_y = np.array([1] * batch_size)\n",
    "\n",
    "    g_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "    print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % save_interval == 0:\n",
    "        noise = np.random.normal(0, 1, (25, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "\n",
    "        fig, axs = plt.subplots(5, 5)\n",
    "        cnt = 0\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                axs[i, j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if epoch % save_interval == 0:\n",
    "            noise = np.random.normal(0, 1, (25, 100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "\n",
    "            fig, axs = plt.subplots(5, 5)\n",
    "            cnt = 0\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    axs[i, j].imshow(gen_imgs[cnt])\n",
    "                    axs[i, j].axis('off')\n",
    "                    cnt += 1\n",
    "            plt.savefig(os.path.join(output_folder, f'epoch_{epoch}.png'))  # Save the figure\n",
    "            plt.close()  # Close the figure to free up memory\n",
    "\n",
    "# Step 5: Generate New Data\n",
    "\n",
    "noise = np.random.normal(0, 1, (10, 100))\n",
    "gen_imgs = generator.predict(noise)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(gen_imgs[i])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_folder, f'final_{i}.png'))  # Save the figure\n",
    "    plt.close()  # Close the figure to free up memory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
