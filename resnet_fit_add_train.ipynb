{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Metrics on Test Data before re-training:\n",
      "Accuracy: 0.6764705882352942\n",
      "Precision: 0.631578947368421\n",
      "Recall: 0.75\n",
      "F1 Score: 0.6857142857142857\n",
      "Shape of train_data before squeezing: (34, 1, 224, 224, 3)\n",
      "Shape of train_data after squeezing: (34, 224, 224, 3)\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6685 - accuracy: 0.6296 - val_loss: 0.5979 - val_accuracy: 0.7143\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6416 - accuracy: 0.5926 - val_loss: 0.5680 - val_accuracy: 0.7143\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6157 - accuracy: 0.5926 - val_loss: 0.5192 - val_accuracy: 0.8571\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5939 - accuracy: 0.6667 - val_loss: 0.4923 - val_accuracy: 0.8571\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5757 - accuracy: 0.6667 - val_loss: 0.4911 - val_accuracy: 0.8571\n",
      "Validation Accuracy during training:\n",
      "[0.7142857313156128, 0.7142857313156128, 0.8571428656578064, 0.8571428656578064, 0.8571428656578064]\n",
      "Metrics on Test Data after re-training:\n",
      "Accuracy: 0.7352941176470589\n",
      "Precision: 0.6842105263157895\n",
      "Recall: 0.8125\n",
      "F1 Score: 0.742857142857143\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import save_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def find_latest_dictionary_csv(folder_path):\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.startswith('dictionary') and f.endswith('.csv')]\n",
    "    if not csv_files:\n",
    "        print(\"No dictionary CSV file found.\")\n",
    "        return None\n",
    "    latest_csv = max(csv_files)\n",
    "    return latest_csv\n",
    "\n",
    "def calculate_metrics(stats_df):\n",
    "    correct_predictions = stats_df[stats_df['ground_truth'] == stats_df['cnn_prediction']]\n",
    "    accuracy = len(correct_predictions) / len(stats_df)\n",
    "    precision = precision_score(stats_df['ground_truth'], stats_df['cnn_prediction'])\n",
    "    recall = recall_score(stats_df['ground_truth'], stats_df['cnn_prediction'])\n",
    "    f1 = f1_score(stats_df['ground_truth'], stats_df['cnn_prediction'])\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def preprocess_fit(image_path):\n",
    "    with fits.open(image_path) as hdul:\n",
    "        image_data = hdul[0].data.astype(np.uint8)\n",
    "        resized_image = cv2.resize(image_data, (224, 224))\n",
    "        rgb_image = cv2.cvtColor(resized_image, cv2.COLOR_GRAY2RGB)\n",
    "    return np.expand_dims(rgb_image, axis=0)\n",
    "\n",
    "\n",
    "def detect_lines_cnn(image_path, model):\n",
    "    preprocessed_image = preprocess_fit(image_path)\n",
    "    prediction = model.predict(preprocessed_image, verbose=0)[0][0]\n",
    "    if prediction >= 0.5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_dictionary(folder_path):\n",
    "    latest_dictionary_csv = find_latest_dictionary_csv(folder_path)\n",
    "    if latest_dictionary_csv:\n",
    "        dictionary_df = pd.read_csv(os.path.join(folder_path, latest_dictionary_csv))\n",
    "        return dictionary_df\n",
    "    else:\n",
    "        print(\"Exiting program.\")\n",
    "        exit()\n",
    "\n",
    "def read_fit_data(folder_path, dictionary_df, model):\n",
    "    filenames = []\n",
    "    ground_truth = []\n",
    "    cnn_predictions = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.fit') and filename.startswith('tic'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            matching_row = dictionary_df[dictionary_df['output'] == filename]\n",
    "            if len(matching_row) == 0:\n",
    "                print(f\"No label found for filename: {filename}\")\n",
    "                continue\n",
    "            label = matching_row.iloc[0]['label']\n",
    "            ground_truth.append(label)\n",
    "            cnn_prediction = detect_lines_cnn(image_path, model)\n",
    "            cnn_predictions.append(cnn_prediction)\n",
    "            filenames.append(filename)\n",
    "    return pd.DataFrame({\n",
    "        'filename': filenames,\n",
    "        'ground_truth': ground_truth,\n",
    "        'cnn_prediction': cnn_predictions\n",
    "    })\n",
    "\n",
    "def train_model_on_test_data(model, folder_path):\n",
    "    dictionary_df = load_dictionary(folder_path)\n",
    "\n",
    "    stats_df = read_fit_data(folder_path, dictionary_df, model)\n",
    "\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(stats_df)\n",
    "    print(\"Metrics on Test Data before re-training:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.fit') and filename.startswith('tic'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            train_data.append(preprocess_fit(image_path))\n",
    "            matching_row = dictionary_df[dictionary_df['output'] == filename]\n",
    "            if len(matching_row) == 0:\n",
    "                print(f\"No label found for filename: {filename}\")\n",
    "                continue\n",
    "            label = matching_row.iloc[0]['label']\n",
    "            train_labels.append(label)\n",
    "    train_data = np.array(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    print(\"Shape of train_data before squeezing:\", train_data.shape)  \n",
    "    train_data = np.squeeze(train_data)  # Remove extra dimension\n",
    "    print(\"Shape of train_data after squeezing:\", train_data.shape)\n",
    "\n",
    "\n",
    "    history = model.fit(train_data, train_labels, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    print(\"Validation Accuracy during training:\")\n",
    "    print(val_accuracy)\n",
    "\n",
    "    # After training, re-evaluate the model on the test data\n",
    "    stats_df_after_training = read_fit_data(folder_path, dictionary_df, model)\n",
    "\n",
    "    # Calculate metrics after re-training\n",
    "    accuracy_after_training, precision_after_training, recall_after_training, f1_after_training = calculate_metrics(stats_df_after_training)\n",
    "    print(\"Metrics on Test Data after re-training:\")\n",
    "    print(\"Accuracy:\", accuracy_after_training)\n",
    "    print(\"Precision:\", precision_after_training)\n",
    "    print(\"Recall:\", recall_after_training)\n",
    "    print(\"F1 Score:\", f1_after_training)\n",
    "\n",
    "\n",
    "folder_path = './Data/fits/'\n",
    "\n",
    "# Load the serialized model\n",
    "serialized_model_path = 'trained_model_2024-04-15_17-04-20.h5'\n",
    "model = load_model(serialized_model_path)\n",
    "\n",
    "# Train the model on the test data\n",
    "train_model_on_test_data(model, folder_path)\n",
    "\n",
    "\n",
    "# serialized_upgraded_model_path = \"resnetModel25IV2024retrained92acc.h5\"\n",
    "# model.save(serialized_upgraded_model_path)\n",
    "\n",
    "# print(\"Upgraded model serialized and saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
